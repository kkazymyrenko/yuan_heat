# -*- coding: utf-8 -*-
"""VQA Warm Start Gradients Based.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1We6-H6mtqktYG7SB0UpqTIhrWSmT3MDY
"""

"""
Parameter-shift gradients
Diagonal Hessian (finite diff) with Positive-Definite fix via Cholesky
Newton-CG optimizer
Nine NLocal ansatz are selected
Multi-run sweeps per ansatz
I added a summary table and plots

"""

import os
import json
import time
import argparse
from dataclasses import dataclass
from typing import List, Dict

import numpy as np
import scipy as sc
from scipy.sparse import csr_matrix, save_npz, load_npz
from scipy.optimize import minimize

# Qiskit
from qiskit.circuit import Parameter
from qiskit.circuit.library import NLocal, RXGate, RYGate, RZGate, CXGate, CCXGate, RealAmplitudes
from qiskit.quantum_info import Statevector


import plotly.graph_objects as go
import plotly.io as pio
pio.renderers.default = "browser"



# Error Metrics


EPS = 1e-15

def norm_vec(x):
    n = np.linalg.norm(x)
    return x / (n + EPS)

def accuracy(a, b) -> float:

    if 0 not in [a, b]:
        return ((b / a) if abs(a) > abs(b) else (a / b)) * 100.0
    return 0.0

def mse_like_percent(u, v):

    u = norm_vec(u)
    v = norm_vec(v)
    return float((u @ v) ** 2 * 100.0)

def trace_error(u, v):

    u = norm_vec(u)
    v = norm_vec(v)
    return float(np.sqrt(max(0.0, 1.0 - (u @ v) ** 2)))





def get_hexahedral_stiffness_matrix(k=1.0, h=1.0):

    gauss = [-1.0 / np.sqrt(3.0), 1.0 / np.sqrt(3.0)]

    def dphi_dxi(i, xi, eta, zeta):
        signs = np.array([
            [-1, -1, -1],
            [ 1, -1, -1],
            [ 1,  1, -1],
            [-1,  1, -1],
            [-1, -1,  1],
            [ 1, -1,  1],
            [ 1,  1,  1],
            [-1,  1,  1]
        ])
        sx, sy, sz = signs[i]
        return np.array([
            0.125 * sx * (1 + sy * eta) * (1 + sz * zeta),
            0.125 * sy * (1 + sx * xi)  * (1 + sz * zeta),
            0.125 * sz * (1 + sx * xi)  * (1 + sy * eta)
        ])

    K = np.zeros((8, 8))
    J = (h / 2.0) * np.eye(3)
    detJ = np.linalg.det(J)
    invJ = np.linalg.inv(J)

    for xi in gauss:
        for eta in gauss:
            for zeta in gauss:
                grads = []
                for a in range(8):
                    dN_ref = dphi_dxi(a, xi, eta, zeta)
                    dN_phys = invJ @ dN_ref
                    grads.append(dN_phys)
                for i in range(8):
                    for j in range(8):
                        K[i, j] += k * float(grads[i] @ grads[j]) * detJ
    return K

def assemble_global_stiffness_matrix(n_elem_per_side, k=1.0, h=1.0, regul=0.0):

    Nx = Ny = Nz = n_elem_per_side + 1
    K_local = get_hexahedral_stiffness_matrix(k=k, h=h)

    def D(N): I = np.eye(N); I[-1, -1] = 0; return I
    def U(N): I = np.eye(N); I[0, 0] = 0; return I
    def T(N): return np.eye(N, k=1)
    def Tt(N): return np.eye(N, k=-1)

    def get_conn_mat(delta, N):
        if delta == 0: return D(N)
        if delta == 1: return T(N)
        if delta == -1: return Tt(N)
        return U(N)

    Dx, Dy, Dz = D(Nx), D(Ny), D(Nz)
    Ux, Uy, Uz = U(Nx), U(Ny), U(Nz)

    positions = [
        (0, 0, 0), (1, 0, 0), (0, 1, 0), (1, 1, 0),
        (0, 0, 1), (1, 0, 1), (0, 1, 1), (1, 1, 1)
    ]

    total_nodes = Nx * Ny * Nz
    K_global = np.zeros((total_nodes, total_nodes), dtype=float)

    for i in range(8):
        for j in range(8):
            dx = positions[j][0] - positions[i][0]
            dy = positions[j][1] - positions[i][1]
            dz = positions[j][2] - positions[i][2]
            if abs(dx) > 1 or abs(dy) > 1 or abs(dz) > 1:
                continue

            Mx = get_conn_mat(dx, Nx)
            My = get_conn_mat(dy, Ny)
            Mz = get_conn_mat(dz, Nz)

            if positions[j][0] != 0 and np.allclose(Mx, Dx): Mx = Ux
            if positions[j][1] != 0 and np.allclose(My, Dy): My = Uy
            if positions[j][2] != 0 and np.allclose(Mz, Dz): Mz = Uz

            kron = np.kron(Mz, np.kron(My, Mx))
            K_global += K_local[i, j] * kron


    K_global *= Nx
    if regul > 0.0:
        K_global += regul * np.eye(total_nodes)
    return K_global

def create_flux_vector_fem3(flux_dict, n_elem_per_side, h=1.0):

    n_nodes_per_side = n_elem_per_side + 1
    n_nodes = n_nodes_per_side ** 3
    frc = np.zeros(n_nodes, dtype=float)

    gauss = [-np.sqrt(1.0 / 3.0), np.sqrt(1.0 / 3.0)]
    def shape_functions(xi, eta):
        return np.array([
            0.25 * (1 - xi) * (1 - eta),
            0.25 * (1 + xi) * (1 - eta),
            0.25 * (1 + xi) * (1 + eta),
            0.25 * (1 - xi) * (1 + eta)
        ])

    def element_node_indices(i, j, k):
        nps = n_nodes_per_side
        return [
            i     +  j*nps +  k*nps*nps,
            (i+1) +  j*nps +  k*nps*nps,
            (i+1) + (j+1)*nps +  k*nps*nps,
            i     + (j+1)*nps +  k*nps*nps,
            i     +  j*nps + (k+1)*nps*nps,
            (i+1) +  j*nps + (k+1)*nps*nps,
            (i+1) + (j+1)*nps + (k+1)*nps*nps,
            i     + (j+1)*nps + (k+1)*nps*nps
        ]

    face_nodes = {
        'x-': [0, 3, 7, 4],
        'x+': [1, 2, 6, 5],
        'y-': [0, 1, 5, 4],
        'y+': [3, 2, 6, 7],
        'z-': [0, 1, 2, 3],
        'z+': [4, 5, 6, 7],
    }
    face_axes = {
        'x-': ('j', 'k'), 'x+': ('j', 'k'),
        'y-': ('i', 'k'), 'y+': ('i', 'k'),
        'z-': ('i', 'j'), 'z+': ('i', 'j'),
    }

    for face, spec in flux_dict.items():
        flux_value = float(spec.get('flux', 1.0))
        coverage = float(spec.get('coverage', 1.0))
        direction = spec.get('direction', face_axes[face][0])

        for i in range(n_elem_per_side):
            for j in range(n_elem_per_side):
                for k in range(n_elem_per_side):
                    if (face == 'x-' and i != 0) or (face == 'x+' and i != n_elem_per_side - 1) or \
                       (face == 'y-' and j != 0) or (face == 'y+' and j != n_elem_per_side - 1) or \
                       (face == 'z-' and k != 0) or (face == 'z+' and k != n_elem_per_side - 1):
                        continue

                    axis_index = {'i': i, 'j': j, 'k': k}[direction]
                    if axis_index > int(coverage * (n_elem_per_side - 1)):
                        continue

                    nodes = element_node_indices(i, j, k)
                    local_face = face_nodes[face]
                    J_det = h * h  # face area (square)

                    for xi in gauss:
                        for eta in gauss:
                            N = shape_functions(xi, eta)
                            for a in range(4):
                                global_node = nodes[local_face[a]]
                                frc[global_node] += flux_value * N[a] * J_det
    return frc

def fix_temp_face_inplace(K, f, face, Nx, Ny, Nz, value=0.0):

    def apply_index(nfix):
        K[nfix, :] = 0.0
        K[:, nfix] = 0.0
        K[nfix, nfix] = 1.0
        f[nfix] = value

    if face == 'x-':
        for k in range(Nz):
            for j in range(Ny):
                apply_index(0 + j*Nx + k*Nx*Ny)
    elif face == 'x+':
        for k in range(Nz):
            for j in range(Ny):
                apply_index((Nx-1) + j*Nx + k*Nx*Ny)
    elif face == 'y-':
        for k in range(Nz):
            for i in range(Nx):
                apply_index(i + 0*Nx + k*Nx*Ny)
    elif face == 'y+':
        for k in range(Nz):
            for i in range(Nx):
                apply_index(i + (Ny-1)*Nx + k*Nx*Ny)
    elif face == 'z-':
        for j in range(Ny):
            for i in range(Nx):
                apply_index(i + j*Nx + 0*Nx*Ny)
    elif face == 'z+':
        for j in range(Ny):
            for i in range(Nx):
                apply_index(i + j*Nx + (Nz-1)*Nx*Ny)
    else:
        raise ValueError(f"Invalid face '{face}'.")

@dataclass
class FEMCache:
    Ksp: csr_matrix
    f: np.ndarray
    ucl: np.ndarray

def build_or_load_fem(expdir, nqb, kappa=1.0, h=1.0, regul=0.0, reuse=True) -> FEMCache:

    assert nqb % 3 == 0, "nqb must be a multiple of 3 so that 2^nqb is a perfect cube."
    side_nodes = 2 ** (nqb // 3)
    n_nodes = side_nodes ** 3
    cache_dir = os.path.join(expdir, "fem_cache")
    os.makedirs(cache_dir, exist_ok=True)
    fK = os.path.join(cache_dir, "K_globalsparse.npz")
    ff = os.path.join(cache_dir, "frc.npy")
    fu = os.path.join(cache_dir, "ucl.npy")

    if reuse and os.path.exists(fK) and os.path.exists(ff) and os.path.exists(fu):
        Ksp = load_npz(fK)
        fvec = np.load(ff)
        ucl = np.load(fu)
        return FEMCache(Ksp=Ksp, f=fvec, ucl=norm_vec(ucl))

    n_elem_per_side = side_nodes - 1
    K = assemble_global_stiffness_matrix(n_elem_per_side, k=kappa, h=h, regul=regul)

    flux_dict = {
        'y-': {'flux': 13.0, 'coverage': 1.0, 'direction': 'i'},
        'z+': {'flux': 15.0, 'coverage': 0.5, 'direction': 'i'},
    }
    fvec = create_flux_vector_fem3(flux_dict, n_elem_per_side=n_elem_per_side, h=h)

    Nx = Ny = Nz = side_nodes

    fix_temp_face_inplace(K, fvec, 'y+', Nx, Ny, Nz, value=4.0)
    fix_temp_face_inplace(K, fvec, 'x-', Nx, Ny, Nz, value=10.0)

    Ksp = csr_matrix(K)

    ucl = sc.sparse.linalg.spsolve(Ksp, fvec).real
    ucl = norm_vec(ucl)

    save_npz(fK, Ksp)
    np.save(ff, fvec)
    np.save(fu, ucl)

    return FEMCache(Ksp=Ksp, f=fvec, ucl=ucl)



# Ansatz


def _ccx_linear_map(n_qubits: int):
    if n_qubits < 3:
        return []
    return [[i, i+1, i+2] for i in range(n_qubits - 2)]

def _cx_linear_map(n_qubits: int):
    if n_qubits < 2:
        return []
    return [[i, i+1] for i in range(n_qubits - 1)]

def build_nlocal(nqb: int, lay: int, rot_blocks, ent_mode: str):

    entanglement_blocks = None
    entangler_map = None
    if ent_mode == "cx_linear":
        entanglement_blocks = CXGate()
        entangler_map = _cx_linear_map(nqb)
    elif ent_mode == "ccx_linear":
        entanglement_blocks = CCXGate()
        entangler_map = _ccx_linear_map(nqb)

    return NLocal(
        num_qubits=nqb,
        rotation_blocks=rot_blocks,
        entanglement_blocks=entanglement_blocks,
        reps=lay,
        entangler_map=(entangler_map if entangler_map else None)
    )

ANSATZ_REGISTRY = {
    # 1. Ry no entanglement
    "ry_none":           lambda nqb, lay: build_nlocal(nqb, lay, [RYGate], "none"),
    # 2. Ry + CX linear
    "ry_cx_linear":      lambda nqb, lay: build_nlocal(nqb, lay, [RYGate], "cx_linear"),
    # 3. Ry + CCX linear
    "ry_ccx_linear":     lambda nqb, lay: build_nlocal(nqb, lay, [RYGate], "ccx_linear"),
    # 4. Rx + Ry no entanglement
    "rxry_none":         lambda nqb, lay: build_nlocal(nqb, lay, [RXGate, RYGate], "none"),
    # 5. Rx + Ry + CX linear
    "rxry_cx_linear":    lambda nqb, lay: build_nlocal(nqb, lay, [RXGate, RYGate], "cx_linear"),
    # 6. Rx + Ry + CCX linear
    "rxry_ccx_linear":   lambda nqb, lay: build_nlocal(nqb, lay, [RXGate, RYGate], "ccx_linear"),
    # 7. Rx + Ry + Rz no entanglement
    "rxryrz_none":       lambda nqb, lay: build_nlocal(nqb, lay, [RXGate, RYGate, RZGate], "none"),
    # 8. Ry + Rx + Rz + CX linear
    "ryrxrz_cx_linear":  lambda nqb, lay: build_nlocal(nqb, lay, [RYGate, RXGate, RZGate], "cx_linear"),
    # 9. Ry + Rx + Rz + CCX linear
    "ryrxrz_ccx_linear": lambda nqb, lay: build_nlocal(nqb, lay, [RYGate, RXGate, RZGate], "ccx_linear"),
}



# Sato cost with shift-rule


def state_from_params(ans, par):

    assert len(par) == ans.num_parameters, "Parameter length mismatch."
    ans_bound = ans.assign_parameters(dict(zip(list(ans.parameters), par)), inplace=False)
    st = Statevector.from_instruction(ans_bound).data

    return np.real(st)

def cost_sato_from_state(stt, Ksp: csr_matrix, fvec: np.ndarray):
    A = float(fvec @ stt)
    B = float(stt @ (Ksp @ stt))

    if abs(B) < EPS:
        return np.inf
    return float(-0.5 * (A * A) / B)

def cost_sato(par, ans, Ksp, fvec):
    psi = state_from_params(ans, par)
    return cost_sato_from_state(psi, Ksp, fvec)

def shift_rule_grad(par, ans, Ksp, fvec, shift=np.pi):

    psi = state_from_params(ans, par)
    A0 = float(fvec @ psi)
    B0 = float(psi @ (Ksp @ psi))
    if abs(B0) < EPS:
        return np.zeros_like(par)

    grad = np.zeros_like(par)
    for i in range(len(par)):
        pp = par.copy(); pp[i] += shift
        pm = par.copy(); pm[i] -= shift

        psi_p = state_from_params(ans, pp)
        psi_m = state_from_params(ans, pm)

        A_p = float(fvec @ psi_p); A_m = float(fvec @ psi_m)
        B_p = float(psi_p @ (Ksp @ psi_p)); B_m = float(psi_m @ (Ksp @ psi_m))

        dA = 0.5 * (A_p - A_m)
        dB = 0.5 * (B_p - B_m)

        grad[i] = -2.0 * (A0 / B0) * dA + (A0 * A0 / (B0 * B0)) * dB
    return grad

def diag_hessian(par, ans, Ksp, fvec, eps=np.pi):
    """
    Only diagonal entries via central finite differences on the scalar cost.
    Then we PD-correct with a diagonal ridge if needed.
    """
    hdiag = np.zeros_like(par)
    f0 = cost_sato(par, ans, Ksp, fvec)
    for i in range(len(par)):
        pp = par.copy(); pp[i] += eps
        pm = par.copy(); pm[i] -= eps
        fp = cost_sato(pp, ans, Ksp, fvec)
        fm = cost_sato(pm, ans, Ksp, fvec)
        hdiag[i] = (fp - 2.0 * f0 + fm) / (eps * eps)
    return hdiag

def make_pos_def(hdiag, max_reg=1e-1):
    """
    Returns a PD diagonal Hessian vector diag(H) by adding lambda to the diagonal if needed.
    """
    hd = hdiag.copy()
    reg = 1e-9
    attempts = 0
    while np.any(hd <= 0.0) and reg <= max_reg:
        hd = hdiag + reg
        reg *= 10.0
        attempts += 1
    if np.any(hd <= 0.0):
        hd = np.maximum(hd, 1e-9)
    return hd



# Optimization loop


def newton_cg_once(ans, Ksp, fvec, par0, maxiter=200, warm_lbfgs=False):
    """
    One Newton-CG optimization with:
    explicit gradient with shift rule
    diagonal Hessian with PD fix
    """
    t0 = time.perf_counter()

    par_init = par0.copy()
    if warm_lbfgs:
        res0 = minimize(
            lambda p: cost_sato(p, ans, Ksp, fvec),
            par_init,
            method="L-BFGS-B",
            jac=lambda p: shift_rule_grad(p, ans, Ksp, fvec),
            options={"maxiter": 20, "disp": False},
            bounds=[(-2*np.pi, 2*np.pi)] * len(par_init),
        )
        par_init = res0.x

    cost_hist = []
    iters_hist = []

    def cb(p):
        c = cost_sato(p, ans, Ksp, fvec)
        cost_hist.append(c)
        iters_hist.append(len(cost_hist))
        print(f"[{len(cost_hist):3d}] Cost: {c:.6e}")


    def fun(p): return cost_sato(p, ans, Ksp, fvec)
    def jac(p): return shift_rule_grad(p, ans, Ksp, fvec)

    def hess(p):
        d = diag_hessian(p, ans, Ksp, fvec)
        d = make_pos_def(d)
        return np.diag(d)

    res = minimize(
        fun, par_init, method="Newton-CG",
        jac=jac, hess=hess, callback=cb,
        options={"maxiter": maxiter, "disp": True}
    )

    t1 = time.perf_counter()
    wall = t1 - t0
    return res, np.array(cost_hist), wall



# Plotting and summary


def plot_qcost_runs(expdir, ans_name, runs_data, ref_cost):

    fig = go.Figure()
    # raw runs
    for i, (its, costs) in enumerate(runs_data):
        fig.add_trace(go.Scatter(x=its, y=costs, mode="lines",
                                 line=dict(width=1), opacity=0.35,
                                 name=f"run {i+1}"))
    # align all on the union of iterations
    all_it = sorted(set().union(*[list(its) for its, _ in runs_data]))
    # interpolate per run
    interp = []
    for its, costs in runs_data:
        y = np.interp(all_it, its, costs)
        interp.append(y)
    M = np.vstack(interp)
    mean = M.mean(axis=0)
    p25 = np.percentile(M, 25, axis=0)
    p75 = np.percentile(M, 75, axis=0)

    fig.add_trace(go.Scatter(x=all_it, y=mean, name="mean", line=dict(width=3)))
    fig.add_trace(go.Scatter(x=all_it + all_it[::-1],
                             y=np.concatenate([p25, p75[::-1]]),
                             fill='toself', fillcolor='rgba(50,205,50,0.3)',
                             line=dict(color='rgba(255,255,255,0)'),
                             hoverinfo='skip', name='25–75%'))

    fig.add_trace(go.Scatter(x=all_it, y=[ref_cost]*len(all_it),
                             mode='lines', name='ref (classical)',
                             line=dict(color='black', dash='dash')))

    fig.update_layout(
        title=f"Qcost vs iteration — {ans_name}",
        xaxis_title="iteration",
        yaxis_title="Qcost",
        template="plotly_white"
    )
    out = os.path.join(expdir, f"plot_qcost_{ans_name}.html")
    pio.write_html(fig, out, auto_open=True)

def plot_accuracy_runs(expdir, ans_name, runs_data, ref_cost):
    """
    Accuracy curve over iterations.
    """
    fig = go.Figure()
    all_it = sorted(set().union(*[list(its) for its, _ in runs_data]))
    acc_interp = []
    for i, (its, costs) in enumerate(runs_data):
        acc = [accuracy(c, ref_cost) for c in costs]
        fig.add_trace(go.Scatter(x=its, y=acc, mode="lines",
                                 line=dict(width=1), opacity=0.35,
                                 name=f"run {i+1}"))
        y = np.interp(all_it, its, acc)
        acc_interp.append(y)
    M = np.vstack(acc_interp)
    mean = M.mean(axis=0)
    p25 = np.percentile(M, 25, axis=0)
    p75 = np.percentile(M, 75, axis=0)

    fig.add_trace(go.Scatter(x=all_it, y=mean, name="mean", line=dict(width=3)))
    fig.add_trace(go.Scatter(x=all_it + all_it[::-1],
                             y=np.concatenate([p25, p75[::-1]]),
                             fill='toself', fillcolor='rgba(50,205,50,0.3)',
                             line=dict(color='rgba(255,255,255,0)'),
                             hoverinfo='skip', name='25–75%'))

    fig.update_layout(
        title=f"Accuracy vs iteration — {ans_name}",
        xaxis_title="iteration",
        yaxis_title="accuracy (%)",
        template="plotly_white"
    )
    out = os.path.join(expdir, f"plot_accuracy_{ans_name}.html")
    pio.write_html(fig, out, auto_open=True)



# Main multi-ansatz runner


def main():
    ap = argparse.ArgumentParser(description="VQA-FEM 3D with Newton-CG + shift-rule")
    ap.add_argument("--expdir", type=str, default="expdir",
                    help="Experiment directory (artifacts & plots).")
    ap.add_argument("--nqb", type=int, default=15,
                    help="Total qubits. MUST be multiple of 3 (perfect cube grid).")
    ap.add_argument("--layers", type=int, default=20, help="Ansatz repetitions (NLocal reps).")
    ap.add_argument("--ansatz-list", type=str, default="rxry_cx_linear",
                    help="Comma-separated ansatz names (see registry).")
    ap.add_argument("--n-runs", type=int, default=5, help="Runs per ansatz.")
    ap.add_argument("--seed", type=int, default=123, help="Base RNG seed.")
    ap.add_argument("--reuse-fem", action="store_true", help="Reuse cached FEM K,f,ucl if present.")
    ap.add_argument("--warmstart-file", type=str, default="",
                    help="Optional .npy parameter file used as initial point (trim/pad as needed).")
    ap.add_argument("--maxiter", type=int, default=200, help="Newton-CG max iterations.")
    ap.add_argument("--warm-lbfgs", type=int, default=0,
                    help="1 to do a brief L-BFGS warmup, else 0.")
    args = ap.parse_args()

    os.makedirs(args.expdir, exist_ok=True)

    # FEM system
    fem = build_or_load_fem(args.expdir, nqb=args.nqb, reuse=args.reuse_fem)
    Ksp, fvec, ucl = fem.Ksp, fem.f, fem.ucl
    ref_cost = cost_sato_from_state(ucl, Ksp, fvec)

    # Build ansatz set
    names = [x.strip() for x in args.ansatz_list.split(",") if x.strip()]
    for nm in names:
        if nm not in ANSATZ_REGISTRY:
            raise ValueError(f"Unknown ansatz '{nm}'. Available: {list(ANSATZ_REGISTRY.keys())}")

    summary_rows = []

    for ans_name in names:
        print("\n" + "="*80)
        print(f"Running ansatz: {ans_name}")
        print("="*80)

        ans = ANSATZ_REGISTRY[ans_name](args.nqb, args.layers)
        npar = ans.num_parameters
        print(f"Num parameters: {npar}")

    # Warm start if provided
        warm_par = None
        if args.warmstart_file and os.path.exists(args.warmstart_file):
            w = np.load(args.warmstart_file)
            if len(w) >= npar:
                warm_par = w[:npar].copy()
            else:
  # pad with zeros
                warm_par = np.zeros(npar)
                warm_par[:len(w)] = w
            print(f"Loaded warm start of length {len(w)} -> used {len(warm_par)}.")

        ans_dir = os.path.join(args.expdir, ans_name)
        os.makedirs(ans_dir, exist_ok=True)

        runs_data = []
        final_accs = []
        final_mse_like = []
        it_counts = []
        times_sec = []

        for run_idx in range(1, args.n_runs + 1):
            print(f"\n--- {ans_name} | run {run_idx}/{args.n_runs} ---")
            seed = args.seed + run_idx
            rng = np.random.default_rng(seed)

            if warm_par is not None:
                par0 = warm_par.copy()
            else:
                par0 = rng.uniform(-1e-3, 1e-3, size=npar).astype(float)

            res, cost_hist, wall = newton_cg_once(
                ans, Ksp, fvec, par0, maxiter=args.maxiter,
                warm_lbfgs=bool(args.warm_lbfgs)
            )

            # Save run artifacts
            run_dir = os.path.join(ans_dir, f"run_{run_idx}")
            os.makedirs(run_dir, exist_ok=True)

            par_opt = res.x
            psi_opt = state_from_params(ans, par_opt)
            np.save(os.path.join(run_dir, "par_opt.npy"), par_opt)
            np.save(os.path.join(run_dir, "psi_opt.npy"), psi_opt)

            wait = np.arange(1, len(cost_hist) + 1)
            out_csv = os.path.join(run_dir, "results.csv")
            import pandas as pd
            pd.DataFrame({"Wait": wait, "Qcost": cost_hist, "ref": ref_cost}).to_csv(out_csv, index=False)

            final_cost = float(cost_hist[-1]) if len(cost_hist) > 0 else float(res.fun)
            meta = {
                "ansatz": ans_name,
                "run": run_idx,
                "final_cost": final_cost,
                "ref_cost": float(ref_cost),
                "final_accuracy_percent": float(accuracy(final_cost, ref_cost)),
                "final_mse_like_percent": float(mse_like_percent(psi_opt, ucl)),
                "iterations": int(len(cost_hist)),
                "time_sec": float(wall),
                "scipy_success": bool(res.success),
                "scipy_message": str(res.message),
            }
            with open(os.path.join(run_dir, "run_meta.json"), "w") as fh:
                json.dump(meta, fh, indent=2)

            runs_data.append((wait, cost_hist))
            final_accs.append(meta["final_accuracy_percent"])
            final_mse_like.append(meta["final_mse_like_percent"])
            it_counts.append(meta["iterations"])
            times_sec.append(meta["time_sec"])

        plot_qcost_runs(ans_dir, ans_name, runs_data, ref_cost)
        plot_accuracy_runs(ans_dir, ans_name, runs_data, ref_cost)

        row = {
            "ansatz": ans_name,
            "mean_final_accuracy": float(np.mean(final_accs)),
            "max_final_accuracy":  float(np.max(final_accs)),
            "min_final_accuracy":  float(np.min(final_accs)),
            "mean_final_mse_like": float(np.mean(final_mse_like)),
            "mean_iters":          float(np.mean(it_counts)),
            "mean_time_sec":       float(np.mean(times_sec)),
            "runs":                int(len(final_accs)),
            "nqb":                 int(args.nqb),
            "layers":              int(args.layers),
        }
        summary_rows.append(row)
        print("\n--- Summary for", ans_name, "---")
        for k, v in row.items():
            print(f"{k}: {v}")

    # Global summary CSV over all ansatz
    import pandas as pd
    summary_df = pd.DataFrame(summary_rows)
    sum_csv = os.path.join(args.expdir, "summary_all_ansatz.csv")
    summary_df.to_csv(sum_csv, index=False)
    print("\nSaved global summary:", sum_csv)
    print(summary_df)


if __name__ == "__main__":
    main()